{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Contents:\n",
    "\n",
    "1) Creating a Classification model for cuisine category prediction. <br>\n",
    "2) Peforming pre-processing on the text, and choosing relevant model for prediction. <br>\n",
    "3) Noting future work that can be done for improving the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 10259,\n",
       " 'cuisine': 'greek',\n",
       " 'ingredients': ['romaine lettuce',\n",
       "  'black olives',\n",
       "  'grape tomatoes',\n",
       "  'garlic',\n",
       "  'pepper',\n",
       "  'purple onion',\n",
       "  'seasoning',\n",
       "  'garbanzo beans',\n",
       "  'feta cheese crumbles']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading file contents of train.json\n",
    "\n",
    "train_file = open(\"Recipe Ingredients/train.json\")\n",
    "train_json = json.load(train_file)\n",
    "train_file.close()\n",
    "train_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]\n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing train_df from the train.json contents\n",
    "\n",
    "train_df = pd.DataFrame(train_json)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting train_df into 80% Training and 20% Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train_df into 80% Training and 20% Validation sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_df.drop('cuisine', axis=1)\n",
    "Y = train_df['cuisine']\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (39774, 2)\n",
      "Y.shape:  (39774,)\n",
      "-----------------------------\n",
      "train_X.shape:  (31819, 2)\n",
      "val_X.shape:  (7955, 2)\n",
      "train_Y.shape:  (31819,)\n",
      "val_Y.shape:  (7955,)\n"
     ]
    }
   ],
   "source": [
    "# Getting overview of training and validation sets shapes\n",
    "\n",
    "print(\"X.shape: \",X.shape)\n",
    "print(\"Y.shape: \",Y.shape)\n",
    "print(\"-----------------------------\")\n",
    "print(\"train_X.shape: \",train_X.shape)\n",
    "print(\"val_X.shape: \",val_X.shape)\n",
    "print(\"train_Y.shape: \",train_Y.shape)\n",
    "print(\"val_Y.shape: \",val_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a classfication model to classify the cuisine\n",
    "- what are some models that you can think of?\n",
    "- what are the tradeoffs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some models that you can think of?\n",
    "\n",
    "We are dealing with text here, i.e. list of ingredients (X variable) and we need to predict the cuisine category. so we will pre-process the ingredients list and preform Count Vectorization on the same. Also, we will label encode the cuisine category (Y variable). <br>\n",
    "Later, we will use <i>Multinomial Naive Bayes Algorithm</i> for classification of the cuisine. We will train our model, get an accuarcy score using the Validation set. <br>\n",
    "Lastly, we will use our model and predict the cuisine categories for the test data.\n",
    "\n",
    "Another alternative can be of using LSTM: Long Short Term Memory Model for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the tradeoffs?\n",
    "\n",
    "Following will be some of the trade-offs:\n",
    "\n",
    "1) If there is any new ingredient in the test recipe, our model will not understand that ingredient, it will treat the ingredient as OOV (Out of Vocabulary word). And here as we using Count Vectorizer, the default behaviour is that it ignores that OOV words, so if that certain ingredient is important, it will be disconsidered by the model. This may affect the prediction accuracy.\n",
    "\n",
    "2) The more vocabulary we try to introduce to the model, the more time-consuming will be the training process for the model, and model may get heavier as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Algorithm:\n",
    "\n",
    "This type of supervised Bayesian approach more popular in Natural Language Processing. It calculates the likelihood for a certain sample and outputs the category having greater probability. One assumption of Naive Bayes is that, it treats each feature to have no relation with other feature. Naive Bayes algorithm is used when their are 2 outcomes (0/1). The term multinomial indicates more than 2 outcomes.<br>\n",
    "\n",
    "In our case, each ingredient list corresponds to a sample, and the 20 cuisines correspond to categories. <br><br>\n",
    "<img align=\"left\" src=\"Algorithms/naive_bayes.png\" height=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Training Set to Feature X and Target Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our feature data of ingredients: X and target data of cuisine: Y from training dataset\n",
    "\n",
    "X = train_X['ingredients']\n",
    "Y = train_Y\n",
    "\n",
    "combined_X = pd.concat([X, val_X['ingredients']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we creating combined_X, what problem it may mitigate?\n",
    "\n",
    "We are including validation data along with training dataset inorder to increase the vocabulary of the model. This will help in handling OOV ingredients to some extent. Although, we won't be using validation data for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Text Data from Feature X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the recipes having special characters or unwanted texts that need to be cleaned\n",
    "\n",
    "recipes_to_be_cleaned = []\n",
    "for recipe in combined_X:\n",
    "    for ingredient in recipe:\n",
    "        if \"oz.\" in ingredient or \"%\" in ingredient:\n",
    "            recipes_to_be_cleaned.append(recipe)\n",
    "            break\n",
    "    if len(recipes_to_be_cleaned)>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'mint leaves', 'corn starch', 'granulated sugar', '1% low-fat milk', 'sweetened condensed milk', 'large egg whites', 'vanilla extract', 'nonfat evaporated milk', 'brown sugar', 'large eggs', 'cream cheese']\n",
      "\n",
      "['celery ribs', 'boneless skinless chicken breasts', 'cayenne pepper', 'medium shrimp', 'olive oil', 'diced tomatoes', 'flat leaf parsley', 'green bell pepper', 'brown rice', 'ham', 'onions', '(    oz.) tomato sauce', 'garlic', 'bay leaf']\n"
     ]
    }
   ],
   "source": [
    "# Showing few examples from data that need text pre-processing\n",
    "\n",
    "print(recipes_to_be_cleaned[0], end=\"\\n\\n\")\n",
    "print(recipes_to_be_cleaned[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Text Data from Feature X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for pre-processing text data from ingredients list\n",
    "# This pre-processing includes removing digits, parenthesis, oz and % representations\n",
    "# It also includes joining words that constitute to be 1 whole ingredient for eg: diced tomatoes\n",
    "\n",
    "import re\n",
    "\n",
    "def getCleanedRecipe(recipe):\n",
    "    \"\"\"\n",
    "    This method takes a recipe's ingredients list as its input, performs pre-processing and provides final ingredients list.\n",
    "    \"\"\" \n",
    "    \n",
    "    for i in range(len(recipe)):\n",
    "        recipe[i] = re.sub(r'\\d+','',recipe[i])\n",
    "        recipe[i] = re.sub(r'[%.]','',recipe[i])\n",
    "        recipe[i] = recipe[i].replace('oz)','')\n",
    "        recipe[i] = recipe[i].replace('(','')\n",
    "        recipe[i] = recipe[i].lstrip()\n",
    "        \n",
    "        listI = recipe[i].split(\" \")\n",
    "        if len(listI) > 1:\n",
    "            ingredient = \"-\".join(listI)\n",
    "            recipe[i] = ingredient\n",
    "            \n",
    "    return recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomato-sauce', 'frozen-chopped-spinach', 'low-fat-milk', 'diced-tomatoes']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstration of method: getCleanedRecipe\n",
    "getCleanedRecipe(['(    oz.) tomato sauce','(10 oz.) frozen chopped spinach','1% low-fat milk','(14.5 oz.) diced tomatoes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing all the ingredients list for feature: X\n",
    "\n",
    "def getCleanedData(X):\n",
    "    \"\"\"\n",
    "    This method takes the feature X, performs pre-processing on the ingredients list of each recipe.\n",
    "    It later joins all the ingredients to make a complete sentence and stores it in a list: tranformed_X.\n",
    "    The transformed_X along with the index from feature X (index= recipe id) is returned as output.\n",
    "    \"\"\"\n",
    "    \n",
    "    transformed_X = []\n",
    "    for recipe in X:\n",
    "        recipe = getCleanedRecipe(recipe)\n",
    "        final_text = \" \".join(recipe)\n",
    "        transformed_X.append(final_text)\n",
    "        \n",
    "    transformed_X = pd.Series(transformed_X, index = X.index)\n",
    "    return transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  ['romaine-lettuce', 'black-olives', 'grape-tomatoes', 'garlic', 'pepper', 'purple-onion', 'seasoning', 'garbanzo-beans', 'feta-cheese-crumbles']\n",
      "Cleaned Text:  romaine-lettuce black-olives grape-tomatoes garlic pepper purple-onion seasoning garbanzo-beans feta-cheese-crumbles\n"
     ]
    }
   ],
   "source": [
    "# Getting cleaned text strings: transformed_X, and printing one example for understanding for the process taken place\n",
    "\n",
    "transformed_X = getCleanedData(combined_X)\n",
    "print(\"Text: \",combined_X[0])\n",
    "print(\"Cleaned Text: \",transformed_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39774x6788 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 430393 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorisation of transformed_X\n",
    "# Count Vectorizer counts each word from and maintains a sparse matrix of all the words from the data.\n",
    "# Each record is encoded into zeros and ones depending on whether the word is present in the record or not.\n",
    "# A voculabulary is also constructed which maintains unique words found in the data, with their corresponding event counts.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(token_pattern='[a-zA-Z-]+')\n",
    "cv.fit_transform(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Length: 6788\n"
     ]
    }
   ],
   "source": [
    "# Getting length of unique words from data: transformed_X\n",
    "print(\"Vocabulary Length:\",len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorized_feature_X.shape:  (31819, 6788)\n"
     ]
    }
   ],
   "source": [
    "# We have created the vocabulary using training + validation data\n",
    "# Now we are building actual feature data: feature_X of training set, which will be fed to the model for training\n",
    "\n",
    "feature_X = getCleanedData(X)\n",
    "vectorized_feature_X = cv.transform(feature_X).toarray()\n",
    "\n",
    "print(\"vectorized_feature_X.shape: \", vectorized_feature_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding of Target Variable Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Label Encoding the target variable Y which includes the cuisine names\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le_Y = le.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15161     french\n",
      "37977      irish\n",
      "4727     mexican\n",
      "11068    mexican\n",
      "30324     indian\n",
      "Name: cuisine, dtype: object\n",
      "[ 5  8 13 13  7]\n"
     ]
    }
   ],
   "source": [
    "# Viewing the first 5 label-encoded values\n",
    "\n",
    "print(Y[:5])\n",
    "print(le_Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brazilian', 'british', 'cajun_creole', 'chinese', 'filipino',\n",
       "       'french', 'greek', 'indian', 'irish', 'italian', 'jamaican',\n",
       "       'japanese', 'korean', 'mexican', 'moroccan', 'russian',\n",
       "       'southern_us', 'spanish', 'thai', 'vietnamese'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the classes of the Label Encoder: these are our cuisine categories\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building using Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying MultinomiaL Navie Bayes Algorithm and Training the model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Training the model\n",
    "mnb.fit(vectorized_feature_X, le_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10621    [vegetable-oil-cooking-spray, prune-puree, bre...\n",
       "37221    [soy-sauce, ginger, varnish-clams, sugar, rice...\n",
       "16752    [chicken-broth, lemon, pepper, garlic-cloves, ...\n",
       "11585    [unsalted-butter, all-purpose-flour, baking-po...\n",
       "29307    [ricotta-cheese, linguine, large-garlic-cloves...\n",
       "Name: ingredients, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing validation dataset feature to be passed to the model for prediction\n",
    "\n",
    "val_X.drop('id', axis=1, inplace=True)\n",
    "val_X = val_X['ingredients']\n",
    "val_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing, Count Vectorization and Prediction on Validation Data\n",
    "\n",
    "val_cleaned = getCleanedData(val_X)\n",
    "val_vectorized = cv.transform(val_cleaned).toarray()\n",
    "val_Y_predicted = mnb.predict(val_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253299811439347"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model on predictions of Validation set\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "val_Y_predicted = le.inverse_transform(val_Y_predicted)\n",
    "accuracy_score(val_Y, val_Y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Recipe Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "# Saving the model to disk\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = 'recipe-classifier-model-using-MultinomialNB.h5'\n",
    "pickle.dump(mnb, open(filename, 'wb'))\n",
    "print(\"Model Saved Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction using Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 18009,\n",
       " 'ingredients': ['baking powder',\n",
       "  'eggs',\n",
       "  'all-purpose flour',\n",
       "  'raisins',\n",
       "  'milk',\n",
       "  'white sugar']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading file contents of test.json\n",
    "\n",
    "test_file = open(\"Recipe Ingredients/test.json\")\n",
    "test_json = json.load(test_file)\n",
    "test_file.close()\n",
    "test_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...\n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...\n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...\n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...\n",
       "4  35687  [ground black pepper, salt, sausage casings, l..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing test_df from the test.json contents\n",
    "\n",
    "test_df = pd.DataFrame(test_json)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [baking powder, eggs, all-purpose flour, raisi...\n",
       "1    [sugar, egg yolks, corn starch, cream of tarta...\n",
       "2    [sausage links, fennel bulb, fronds, olive oil...\n",
       "3    [meat cuts, file powder, smoked sausage, okra,...\n",
       "4    [ground black pepper, salt, sausage casings, l...\n",
       "Name: ingredients, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting feature test_X: ingredients to be passed for prediction\n",
    "\n",
    "test_X = test_df['ingredients']\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing, Count Vectorization and Prediction on Test Data\n",
    "\n",
    "test_cleaned = getCleanedData(test_X)\n",
    "test_vectorized = cv.transform(test_cleaned).toarray()\n",
    "Y_predicted = mnb.predict(test_vectorized)\n",
    "Y_predicted = le.inverse_transform(Y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Predicted Output as JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       cuisine\n",
       "0  18009   southern_us\n",
       "1  28583   southern_us\n",
       "2  41580       italian\n",
       "3  29752  cajun_creole\n",
       "4  35687       italian"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the cuisine predictions into dataframe\n",
    "\n",
    "Y_predicted_df = pd.DataFrame(test_df['id'])\n",
    "Y_predicted_df['cuisine'] = Y_predicted\n",
    "Y_predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output File Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "# Saving the dataframe of cuisine predictions to disk in JSON Format\n",
    "\n",
    "Y_predicted_df.to_json(\"Recipe Ingredients/test_output_using_MultinomialNB.json\", orient='records', indent=3)\n",
    "print(\"Output File Saved Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work:\n",
    "\n",
    "We will use LSTM Model for Model Building and Training phases and then compare the results of the 2 models on basis of their accuracy scores, as well their output predictions.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------\n",
    "-----------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
